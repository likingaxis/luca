---
{"dg-publish":true,"permalink":"/anno-2/reti/reti-lez-11/"}
---

## Differenza tra congestione ğŸŒ e controllo di flusso ğŸŒŠğŸ“¶
- Controllo di flusso
	- esso indica quando abbiamo un mittente che manda troppi pacchetti velocemente
- congestione ğŸŒ 
	- quando n mittenti trasmettono tutto troppo velocemente
Ã¨ un problema importantissimo del networking perchÃ© causa:
- ritardi 
- perdita di pacchetti

### Casistiche di congestione ğŸŒ
#### Scenario 1 ğŸ”µ
- abbiamo buffer illimitati
- capacitÃ  di collegamento R
	- la massima quantitÃ  di dati (in bit al secondo) che un collegamento puÃ² trasportare
- due flussi di comunicazione
- nessuna ritrasmissione ğŸ”
	- niente errori

![Pasted image 20250410175431.png](/img/user/ANNO%202/RETI/fotret/Pasted%20image%2020250410175431.png)
il tutto ovviamente Ã¨ cosÃ¬ perfetto da risultare lineare
>[!bug] visto che il router e il collegamento Ã¨ condiviso tra due insiemi di host
>appena si supera R/2 il collegamento subisce dei rallentamenti causando congestione ğŸŒ
>ovviamente visto che $\delta_in$ e $\delta_out$ escono in modo 1:1 
>appena superano R/2 accade quanto detto
>![Pasted image 20250410175958.png|500](/img/user/ANNO%202/RETI/fotret/Pasted%20image%2020250410175958.png)
#### Scenario 2 ğŸŸ¢
abbiamo sempre
- un router
perÃ² stavolta
- buffer finiti
- la possibilitÃ  che alcuni pacchetti debbano essere ritrasmessi
	- quando il buffer Ã¨ pieno
Aggiungiamo inoltre una differenza tra
- input del livello di applicazione
	- $\lambda_{in}$
	- non include le ritrasmissioni
- input del livello di trasporto
	- $\lambda'_{in}$ 
	- include le ritrasmissioni
	- viene anche chiamato carico offerto alla rete
cosÃ¬ facendo possiamo prendere per ovvio che 
$$\lambda'_{in} \geq \lambda_{in}$$
![Pasted image 20250410180557.png](/img/user/ANNO%202/RETI/fotret/Pasted%20image%2020250410180557.png)
Prendiamo una situazione ancora perfetta:
- il mittente sa se il buffer del router Ã¨ pieno oppure no
	- procede a inviare solo quando si puÃ² 
	- non viene generata congestione ğŸŒ
input=troughput fino a R/2 
![Pasted image 20250410180810.png](/img/user/ANNO%202/RETI/fotret/Pasted%20image%2020250410180810.png)
Prendiamo una situazione meno perfetta:
- i pacchetti possono essere scartati dal router quando il suo buffer Ã¨ pieno
- il mittente perÃ² sa quando ciÃ² accade quindi lo ritrasmette
![Pasted image 20250410180930.png](/img/user/ANNO%202/RETI/fotret/Pasted%20image%2020250410180930.png)
in questo caso si perde un po di troughput ğŸ“‰ rispetto all'input
![Pasted image 20250410181047.png](/img/user/ANNO%202/RETI/fotret/Pasted%20image%2020250410181047.png)
Prendiamo una situazione realistica
- i pacchetti vengono persi e scartati dal router
	- causa: buffer pieni ğŸ“›
	- Ã¨ richiesta una ritrasmissione ğŸ”
se il mittente invia un pacchetto ma a causa della congestione ğŸŒ esso Ã¨ rallentato ğŸ¢
- allora quello che succede Ã¨ che l'ACK ğŸ“¬ che il mittente attendeva arriverÃ  in ritardo
- il mittente pensa che il pacchetto sia perso quindi entra in timeout â±ï¸per l'ACK ğŸ“¬ non ricevuto
	- rimanda il pacchetto
	- sostanzialmente invia due copie uguali al destinatario
	- timeout â±ï¸ (prematuro perchÃ© non sa della congestione ğŸŒ)
![Pasted image 20250410181629.png](/img/user/ANNO%202/RETI/fotret/Pasted%20image%2020250410181629.png)
![Pasted image 20250410181647.png](/img/user/ANNO%202/RETI/fotret/Pasted%20image%2020250410181647.png)
- il troughput Ã¨ ridotto perchÃ© abbiamo piÃ¹ lavoro inutile

#### Scenario 3 ğŸŸ£
- abbiamo 4 mittenti
- percorsi multi- hop
	- Un **percorso multi-hop** Ã¨ un tragitto in rete in cui i dati devono **attraversare piÃ¹ di un router o nodo intermedio** per arrivare a destinazione.
- Ã¨ presente sia timeout â±ï¸ che ritrasmissione ğŸ”
Leggi la domanda e la risposta sotto:
![Pasted image 20250410182434.png](/img/user/ANNO%202/RETI/fotret/Pasted%20image%2020250410182434.png)
- PerchÃ© vengono scartati? i pacchetti blu?
	- sostanzialmente vengono scartati perchÃ© quelli rossi arrivano prima di quelli blu e quindi si prendono tutta la banda
	- quelli rossi subiscono la congestione ğŸŒ
![Pasted image 20250410183302.png](/img/user/ANNO%202/RETI/fotret/Pasted%20image%2020250410183302.png)
- quando abbiamo una congestione ğŸŒ i collegamenti upstream sono limitati e quindi stiamo sprecando la loro capacitÃ  trasmissiva
- in questo grafico si puÃ² vedere come sia tutto altalenante
### Riassunto sui vari grafici ğŸ“Š
| **Descrizione**                                                                      | **Grafico a destra**                      |
| ------------------------------------------------------------------------------------ | ----------------------------------------- |
| ğŸ”¸ **Il throughput non puÃ² mai superare la capacitÃ .**                               | ![[Pasted image 20250410184107.png\|130]] |
| ğŸ”¸ **Il ritardo aumenta mentre ci si avvicina alla capacitÃ .**                       | ![[Pasted image 20250410184115.png\|130]] |
| ğŸ”¸ **La perdita/ritrasmissione ğŸ” diminuisce il throughput effettivo.**                 | ![[Pasted image 20250410184122.png\|130]] |
| ğŸ”¸ **I duplicati non necessari ğŸ—‘ï¸ diminuiscono ulteriormente il throughput effettivo.** | ![[Pasted image 20250410184128.png\|130]] |
| ğŸ”¸ **CapacitÃ  a monte/buffer sprecati per pacchetti persi a valle.**                 | ![[Pasted image 20250410184134.png\|130]] |

## Come controllare la congestione ğŸŒğŸ§ ğŸŒ
#### network assisted
Senza l'aiuto della rete(metodo che usa TCP)
- i dispositivi che si scambiano le info devono dedurre ciÃ² che accade
	- attraverso il ritardo e le perdite dei pacchetti
![Pasted image 20250410184656.png](/img/user/ANNO%202/RETI/fotret/Pasted%20image%2020250410184656.png)
Con l'aiuto della rete
- per capirlo fa come il dottore, vede i sintomi
- i router forniscono un feedback diretto all'host 
	- attraverso un pacchetto chiamato chokepacket
	- lo avvisa dello stato di congestione ğŸŒ
- un router marca i pacchetti dicendo il suo stato di congestione ğŸŒ
	- in modo che poi il destinatario li legga e informi il mittente della situazione
- servono non solo per indicare cause di congestione ğŸŒ ma anche solo impostare dei tassi a cui inviare i pacchetti
viene usato nei protocolli
- TCP ECN
- ATM
- DECbit
### Recuppino di trasmissione dati affidabile e controllo della congestione ğŸ“ŠğŸŒ ğŸŒ ğŸ”ğŸ“¡
- trasmissione dati affidabile
	- Una trasmissione dati affidabile consente di ridurre la perdita ğŸ“‰ e la corruzione dei pacchetti
	- queste cose possono essere causate dalla congestione ğŸŒ
- controllo congestione ğŸŒ
	- Avere un controllo della congestione ğŸ“ŠğŸŒ ğŸŒ ci consente di risolverla o comunque di ridurla notevolmente
		- evita il "collasso di congestione ğŸŒ"
## Cambiamenti del TCP ğŸ”§
- in origine aveva un controllo di congestione ğŸŒ end-to-end
- ora ci sono delle versioni piÃ¹ recenti che consentono 
	- di avere esplicitamente dalla rete le info sulla congestione ğŸŒ
### come avere controllo sulla congestione end-to-end ğŸŒ ğŸ“ˆ?
per farlo si definisce un tasso di invio ovvero:
- quanti byte al secondo posso spedire?
	- per saperlo si utilizza la finestra della congestione ğŸŒ 
![Pasted image 20250411160344.png|400](/img/user/ANNO%202/RETI/fotret/Pasted%20image%2020250411160344.png)
- In questa foto ci interessa in particolare la cwnd congestion window
	- che viene regolata dinamicamente in base allo stato di congestione ğŸŒ della rete
il tasso di invio viene calcolato dalla seguente formula
$$ tasso \ di \ invio \approx \frac{cwnd}{RTT} \ byte/s$$
- ogni volta che vengono inviati i byte della finestra cwnd 
	- si attende anche l'RTT quindi si dimezzano
- ovviamente il mittente limita la trasmissione dei dati che saranno
	- $ultimo\_byte\_inviato-ultimo\_byte\_acked\leq cwnd$ 
	- devono per forza di cosa essere minori uguali perchÃ©
		- la differenza tra l'ultimo byte inviato e l'ultimo byte verificato ci porta a sapere quanti sono ancora in volo
		- ovviamente il dato deve essere minore o uguale a quella che Ã¨ la nostra finestra di congestione ğŸŒ CWND
- Non bisogna porre solo attenzione al massimo della finestra della congestione ğŸŒ bensÃ¬ anche ai limiti della finestra del destinatario RWND
	- quindi il numero di byte in volo deve essere anche $\leq rwnd$
$$ultimo\_byte\_inviato-ultimo\_byte\_acked\leq min \{rwnd,cwnd\}$$
>[!tip] in realtÃ  si dovrebbe assumere che la finestra di ricezione rwnd sia comunque piÃ¹ grande di quella di congestione ğŸŒ quindi si potrebbe anche trascurare

### come gestire il tasso di invio ğŸ•¹ï¸
ora che sappiamo calcolarlo come facciamo perÃ² a gestirlo in relazione al fatto che non vogliamo che la congestione ğŸŒ peggiori?
- per farlo cerchiamo di punire o premiare il mittente in base ad una perdita presente o meno
- se c'Ã¨ una perdita dimezzo la velocitÃ  di invio
- se non avvengono aumento la velocitÃ  di 1MSS ad ogni RTT
	- MSS: invio un segmento dati in piÃ¹ ogni volta
	- RTT: invio di un dato + feedback di rientro ğŸ“¤ğŸ“¥
Questo fenomeno viene chiamato AIMD
- sta per Additive Increase, Multiplicative Decrease
![Pasted image 20250411162431.png](/img/user/ANNO%202/RETI/fotret/Pasted%20image%2020250411162431.png)

### TCP Reno ğŸŒªï¸
- Ãˆ un algoritmo che implementa le idee di AIMD
	- dimezza quando un triplo ACK ğŸ“¬ ha lo stesso numero di ACK ğŸ“¬
		- entra poi nella fase di fast recovery(spiego meglio dopo)
	- Taglio a 1 MSS quando abbiamo invece una perdita dovuta a un ACK ğŸ“¬ non ricevuto
		- il timeout â±ï¸ Ã¨ scaduto
TCP Tahoe Ã¨ una versione piÃ¹ vecchia e semplice
- per qualsiasi perdita toglieva 1 MSS e passava a slow start
>[!tip] attraverso questi algoritmi miglioriamo stabilitÃ  e congestione ğŸŒ generale

## Concetto di slow start ğŸ¢ğŸ’¨
- la partenza Ã¨ con una frequenza bassa di invio
	- ma cresce esponenzialmente 
	- fino a quando non si verifica una perdita
- inizio:
	- cwnd=1 MSS
- durante:
	- cwnd raddoppiato ad ogni RTT
- perdita:
	- riduco gli MSS
![Pasted image 20250411164115.png|300](/img/user/ANNO%202/RETI/fotret/Pasted%20image%2020250411164115.png)

#### Da esponenziale a lineare ğŸ“‰â¡ï¸ğŸ“ˆ
- avviene quando il cwnd assume piÃ¹ della metÃ  del suo valore prima del timeout â±ï¸
- per aggiustare il tiro viene usata la variabile `sstresh`
- tiene conto delle perdite per ridurle in futuro
	- quando siamo in slow start `cwnd` cresce
	- inizialmente `sstresh=64 KB`
	- appena `cwnd` raggiunge in questo caso `64 KB` 
		- cresce linearmente
	- appena avviene un fault ğŸš¨
		- `sstresh=cwnd/2`e
		- avviene una cosa in base al tipo di fault
ğŸŸ¥ **Caso 1: fault tramite timeout â±ï¸** (grave)
- `cwnd = 1 MSS` â†’ si **riparte da zero** (fase di **slow start**)
ğŸ” TCP Ã¨ super prudente: pensa che la rete sia molto congestionata.

ğŸŸ¦ **Caso 2: fault dovuto a triplo ACK ğŸ“¬ duplicato** (meno grave, Reno)
- `ssthresh = cwnd / 2`
- `cwnd = ssthresh` o poco sopra
- Entra in **fast recovery**(vedi tra poco), poi passa alla **congestion avoidance**
#### Macchina a stati che chiede all'esame ğŸ§¾
![Pasted image 20250411170120.png](/img/user/ANNO%202/RETI/fotret/Pasted%20image%2020250411170120.png)
>[!tip]- spiegazione(prova a farla da solo prima di leggere qua sotto)
>spiegazione falla tra poco

##### âœ… **Riassunto: Controllo della Congestione TCP**
ğŸ”µ 1. **Quando arriva un nuovo ACK ğŸ“¬**

- Il mittente **puÃ² spostare in avanti la sua finestra di invio** (scorre verso destra).
    
- Questo significa che **puÃ² inviare nuovi segmenti**, perchÃ© uno Ã¨ stato confermato (ACK ğŸ“¬ ricevuto) e quindi "libera spazio".

ğŸŸ¢ 2. **Fase di Congestion Avoidance ğŸ›£ï¸**
- La **finestra `cwnd` cresce lentamente**, in modo **lineare**.
- Per ogni nuovo ACK ğŸ“¬ ricevuto:
	- $incremento=MSS*\frac{MSS}{cwnd}$
- In un intero RTT, ci si aspetta un numero di ACK ğŸ“¬= $\frac{cwnd}{MSS}$
- quindi abbiamo un incremento di 1 MSS ad ogni RTT perchÃ© si semplificano MSS e cwnd
ğŸ” Questo Ã¨ lâ€™**incremento additivo dellâ€™AIMD**.

ğŸŸ  3. **Fase di Fast Recovery âš¡**
- Scatta **dopo un triplo ACK ğŸ“¬ duplicato** (segnale di perdita).
	- Il mittente **non avanza la finestra** finchÃ© non arriva un ACK ğŸ“¬ nuovo.
	- PerÃ²: per ogni ACK ğŸ“¬ duplicato, TCP **aumenta temporaneamente `cwnd`**, per poter eventualmente trasmettere un nuovo pacchetto.
	- un nuovo pacchetto quindi viene inviato circa ogni mezzo RTT
- Appena arriva lâ€™ACK ğŸ“¬ del segmento perso, **si esce dalla fast recovery**.

ğŸ”´ 4. **Durata della Fast Recovery âš¡**
- tutta la fast dura **circa 1 RTT**, cioÃ¨ il tempo necessario affinchÃ© lâ€™ACK ğŸ“¬ del segmento ritrasmesso torni al mittente.
#### TCP CUBIC ğŸ“¦ğŸš€
Algoritmo che cerca di sfruttare meglio le bande moderne che sono molto veloci
rispetto a TCP Reno che cresceva linearmente, questo cresce di piÃ¹
- dato un $W_{max}$
	- che indica la dimensione della finestra di quando Ã¨ avvenuta una perdita
- quando avviene una perdita si dimezza la velocitÃ  di trasmissione ma si ritorna piÃ¹ velocemente a $W_{max}$ avvicinandosi piÃ¹ lentamente
![Pasted image 20250411174707.png](/img/user/ANNO%202/RETI/fotret/Pasted%20image%2020250411174707.png)
possiamo vedere da questa foto qua sopra come sia molto piÃ¹ veloce
Per capire quanto tempo ci metterÃ  per raggiungere la dimensione $W_{max}$ si usa una variabile $K$
- appena si Ã¨ lontani da $K$ significa che si puÃ² andare piÃ¹ veloci
- appena ci si avvicina bisogna essere piÃ¹ cauti perchÃ© significa che ci si sta avvicinando al limite
- tutto ciÃ² Ã¨ calcolato da una funzione cubica che non stiamo a precisare con diversi parametri
- TCP cubic Ã¨ di default nei server linux
il problema di questo TCP Ã¨ che si raggiunge ogni volta il collo di bottiglia
- si intende che ogni volta si cerca di superare $W_{max}$ 
	- invece non si dovrebbe far straripare il buffer
foto che fa vedere che il buffer Ã¨ sempre strapieno e poi si creano problemi di congestione âš ï¸ ğŸŒ
![Pasted image 20250411180007.png](/img/user/ANNO%202/RETI/fotret/Pasted%20image%2020250411180007.png)
>[!tip] quindi l'obiettivo Ã¨ quello di tenere il buffer quasi pieno ma mai completamente

![Pasted image 20250411180141.png](/img/user/ANNO%202/RETI/fotret/Pasted%20image%2020250411180141.png)
### Soluzione: TCP vegas â™ ï¸ğŸ¯
TCP Vegas Ã¨ una evoluzione di CUBIC, cerca sostanzialmente ogni volta di calcolare una stima di quello che puÃ² essere il limite per non raggiungerlo mai
Sta letteralmente facendo edging
Come si fa questa stima?
per calcolarla viene 
- ogni volta calcolato l'RTT attuale e lo chiama $RTT_{measured}$
- confrontato questo attuale con quello minimo rilevato
	- non pensare che minimo sia peggio
		- minimo significa che ci ha messo poco ritardo
- questa differenza tra i due si calcola perchÃ© ci serve per capire se stiamo avendo piÃ¹ ritardo del normale (il min indica una situazione ideale senza congestione ğŸŒ)

successivamente calcola il troughput ideale con $$\frac{cwnd}{RTT_{min}}$$ e lo confronta con quello reale dovuto a $$\frac{byte\_sended}{RTT_{measured}}$$
- Se il throughput reale â‰ˆ quello ideale
	- rete libera ğŸŸ¢
	- si puÃ² aumentare `cwnd`
- Se il throughput reale â‰ª quello ideale 
	- rete congestionata ğŸ”´ 
	- serve ridurre `cwnd`
con questo metodo
- le perdite non sono forzate
- si massimizza il troughput ğŸš€
- il ritardo rimane basso
>[!tip] ci sono dei TCP che adottano un approccio basato su ritardi come
>- BBR della rete interna di Google ğŸŒğŸ”
>- sono distribuiti ovvero su larga scala

### ECN(Explicit Congestion Notification)
alcune implementazioni di TCP spesso hanno un controllo della congestione ğŸ“ŠğŸŒ ğŸŒ aiutato dalla rete stessa
- un router di rete imposta due bit ECN che sono nell'intestazione IP
	- questi due bit indicano la congestione ğŸŒ 
	- se li imposto a `10` significa che questi bit sono abilitati
	- se un router rileva congestione ğŸŒ li mette a `11`
- il destinatario non puÃ² modificare mai il protocollo TCP perÃ² puÃ² inviare un ACK ğŸ“¬ con un bit speciale chiamato 
	- ECE che se Ã¨ a `1` significa che c'Ã¨ congestione ğŸŒ
- ECN viene negoziato nella fase di handshake iniziale dove:
	- sia mit che dest devono dire:  ğŸ‘‰ â€œ**SÃ¬, supporto ECN**â€

![Pasted image 20250411183520.png|500](/img/user/ANNO%202/RETI/fotret/Pasted%20image%2020250411183520.png)


#### Il TCP Ã¨ fair?
>[!tip] precisazione su fairness
>se ho k connessioni tutte con la stessa banda
>- ho equitÃ  tra di loro?
>- ho un troughput = a $\frac{R}{K}$
>	- R Ã¨ la capacitÃ  di rete
>	- K sono le connessioni
>![Pasted image 20250411184355.png|400](/img/user/ANNO%202/RETI/fotret/Pasted%20image%2020250411184355.png)

Ora parliamo di questo applicato proprio al TCP:
nella foto sottostante abbiamo un esempio con due troughput diversi che lavorano sulla stessa banda
alla fine si riesce a vedere che Ã¨ fair se perÃ² le connessioni hanno un equilibrio tipo:
- hanno stesso RTT
- numero di connessioni costante
- tutte le connessioni sono lineari e non sono in slow start(esponenziali)
#### Invece UDP Ã¨ fair?
- visto che abbiamo detto che le app video e audio non usano TCP ma UDP per garantire minore latenza poniamoci il dubbio se anche lui Ã¨ fair
	- UDP puÃ² essere unfair
	- in un caso di banda condivisa puÃ² inviare di piÃ¹ a un determinato destinatario
#### Concetto di TCP paralleli ğŸª„ğŸ“¶
semplicemente quando apri piÃ¹ schede del browser stai aprendo piÃ¹ connessioni TCP
questo trucco puÃ² quindi bypassare la fairness perchÃ© ti permette di fare piÃ¹ connessioni quindi avere piÃ¹ banda
### Come calcolare il troughput medio ğŸ§®ğŸ“
semplicemente fai $$troughput\_med=\frac{3}{4}*\frac{W}{RTT}$$
dove 
- W dimensione della finestra poco prima di una perdita
![Pasted image 20250411190027.png](/img/user/ANNO%202/RETI/fotret/Pasted%20image%2020250411190027.png)

#### Evoluzioni di TCP e UDP ğŸ§¬
- TCP e UDP dominano il trasporto da **oltre 40 anni**.
- Ma i contesti moderni (cloud, 5G, data center, satellite, ecc.) hanno esigenze molto diverse â†’ servono **varianti specializzate di TCP**.
ğŸ“‹ Tabella riassuntiva:

|**Scenario**|**Sfida principale**|
|---|---|
|**Long, fat pipes**|Molti pacchetti "in volo" â†’ una perdita interrompe tutto (es. WAN ad alta banda)|
|**Reti wireless**|Perdita dovuta a rumore/mobilitÃ , ma TCP la interpreta come congestione ğŸŒ|
|**Link ad alto ritardo**|RTT altissimi (es. satellite) â†’ risposta lenta, crescita lenta della finestra|
|**Data center**|Reti con latenza bassissima, ma altissima sensibilitÃ  a ogni millisecondo di ritardo|
|**Flussi in background**|Flussi TCP non prioritari, devono adattarsi senza disturbare gli altri|
Il TCP ha un problema delle Long, Fat pipes ovvero:
- pacchetti da inviare lontano (long) (alto RTT)
- e con alta capacitÃ  di banda (Fat)(tanti Gbps di banda)
Questo problema ci riporta a un esempio che scrivo sotto ma che in sostanza ci fa capire che per raggiungere la banda prefissata dovremmo praticamente avere 
- 1 pacchetto perso ogni 5 miliardi
![Pasted image 20250411191414.png|500](/img/user/ANNO%202/RETI/fotret/Pasted%20image%2020250411191414.png)
W viene calcolato da: $Throughput\_Â desideratoÃ—RTT$

>[!success] In questi casi servono varianti di TCP per risolvere il problema:
> - TCP BIC, TCP HighSpeed, TCP CUBIC (default in Linux),
> - oppure nuove soluzioni come **BBR**,
> - oppure approcci come **QUIC** sopra UDP.

## QUIC ğŸš€ğŸ”—
Ã¨ un protocollo applicativo che si trova sopra a UDP 
- serve per aumentare le performance di HTTP
- usato in app di google e in molti server
![Pasted image 20250411191901.png|400](/img/user/ANNO%202/RETI/fotret/Pasted%20image%2020250411191901.png)
##### PerchÃ© QUIC Ã© meglio?
- QUIC usa algoritmi per fare il controllo degli errori simili a quelli di TCP
	- rileva perdite
	- regola il flusso
- con un solo handshake(andata-ritorno) stabilisce:
	- affidabilitÃ 
	- controllo della congestione ğŸ“ŠğŸŒ ğŸŒ
	- utilizza autenticazioni sicure come TLS
- Consente di fare del multiplexing degli stream
	- piÃ¹ flussi simultanei separati
	- condividono stesso controllo della congestione ğŸ“ŠğŸŒ ğŸ¤ğŸŒ ğŸŒ
	- TCP fa schifo rispetto a questo perchÃ© TCP soffre di
		- head-of-line blocking ğŸš«ğŸ“¦
		- il primo pacchetto mancante **blocca tutta la fila dietro**.
			- se un merdone blocca il cesso Ã¨ tutto intasato e bloccato

### TCP VS QUIC ğŸ¥Š
![Pasted image 20250411192545.png](/img/user/ANNO%202/RETI/fotret/Pasted%20image%2020250411192545.png)
si puÃ² vedere una notevole differenza
QUIC con un solo handshake fa tutto e puÃ² subito iniziare a inviare i dati

Gif che fa vedere che che non c'Ã¨ HOL blocking, se uno si blocca vanno gli altri
![Desktop2025.04.11-19.27.05.01-Trim-ezgif.com-video-to-gif-converter.gif|700](/img/user/ANNO%202/RETI/fotret/Desktop2025.04.11-19.27.05.01-Trim-ezgif.com-video-to-gif-converter.gif)
