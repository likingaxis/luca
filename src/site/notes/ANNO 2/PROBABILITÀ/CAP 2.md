---
{"dg-publish":true,"permalink":"/anno-2/probabilita/cap-2/"}
---

# ğŸ“˜ Capitolo 2 â€“ Variabili casuali discrete e aspettativa

## ğŸ¯ Introduzione

Nel capitolo precedente abbiamo visto come la probabilitÃ  serva a stimare quanto spesso accadono certi eventi.  
Ora facciamo un passo oltre: vogliamo capire **quali valori numerici puÃ² assumere un evento casuale** e, soprattutto, **quanto ci aspettiamo in media da esso**.

Per farlo introduciamo uno strumento fondamentale: la **variabile casuale**, detta anche *variabile aleatoria*.

---

## ğŸ”¹ 2.1 â€“ Variabili casuali e aspettativa

Una **variabile casuale (o aleatoria)** Ã¨ una funzione che associa a ciascun possibile esito di un esperimento casuale un numero reale:

$$
X : \Omega \to \mathbb{R}
$$

dove:

- $\Omega$ Ã¨ lo **spazio campionario**, cioÃ¨ lâ€™insieme di tutti i possibili esiti;  
- $X(\omega)$ Ã¨ il numero che la variabile assegna allâ€™esito $\omega$.

ğŸ‘‰ Quindi $X$ **non Ã¨ un evento**, ma una quantitÃ  che dipende dal caso.

---

### ğŸ”¸ Esempio 1 â€“ Il lancio di un dado

Lanci un dado a sei facce.

$$
\Omega = \{1, 2, 3, 4, 5, 6\}
$$

Definiamo la variabile casuale:

$$
X(\omega) = \omega
$$

In altre parole, $X$ Ã¨ il numero uscito sul dado.  
Ogni valore $x$ ha probabilitÃ :

$$
\Pr(X = x) = \frac{1}{6}, \quad x = 1, 2, \dots, 6
$$

---

## ğŸ”¹ 2.1.1 â€“ Il concetto di aspettativa

Il **valore atteso** o **aspettativa**, indicato con $E[X]$, Ã¨ la **media ponderata** di tutti i valori che $X$ puÃ² assumere, usando come peso le loro probabilitÃ :

$$
E[X] = \sum_x x \cdot \Pr(X = x)
$$

ğŸ‘‰ In parole semplici:  
$E[X]$ rappresenta il **valore medio teorico** che otterremmo se ripetessimo lâ€™esperimento infinite volte.

---

### ğŸ”¸ Esempio 2 â€“ La media del dado

$$
E[X] = \frac{1 + 2 + 3 + 4 + 5 + 6}{6} = 3.5
$$

âš ï¸ **Nota:** 3.5 non Ã¨ un valore che puÃ² uscire, ma Ã¨ la media teorica dei risultati.  
Se lanci un dado molte volte, la media dei numeri ottenuti si avvicinerÃ  a 3.5.

ğŸ‘‰ Ãˆ un concetto astratto ma **predittivo**: ci dice â€œin mediaâ€ cosa aspettarci dal fenomeno.

---

## ğŸ”¹ 2.1.2 â€“ Differenza tra evento e variabile casuale

Un **evento** Ã¨ una proposizione che puÃ² essere vera o falsa (es. â€œesce 6â€).  
Una **variabile casuale** assegna un numero a ciascun evento possibile.

Esempio:

- Evento: â€œesce un numero pariâ€  
  â†’ $\Pr(\text{pari}) = \frac{3}{6} = 0.5$

- Variabile casuale: â€œil numero uscitoâ€  
  â†’ $E[X] = 3.5$

ğŸ“˜ Quindi $E[X]$ **non Ã¨ una probabilitÃ **, ma la **media** dei valori numerici che la variabile puÃ² produrre.

---

## ğŸ”¹ 2.1.3 â€“ Famiglie di variabili casuali: indici sopra e sotto

Spesso dobbiamo descrivere piÃ¹ variabili casuali collegate, come in una sequenza di esperimenti.

$$
X_1, X_2, \dots, X_n
$$

rappresentano $n$ variabili distinte, ad esempio i risultati di piÃ¹ lanci di un dado.

- $X_1, X_2, X_3$: risultati del primo, secondo, terzo dado  
- $(X_1)^2$ o $X^2$: il quadrato del valore di $X$, utile per la varianza o per $E[X^2]$

---

### ğŸ”¸ Esempio pratico

Lanci due dadi tre volte.

- $X^1_1$: risultato del primo dado al primo lancio  
- $X^2_1$: risultato del secondo dado al primo lancio  
- $X^1_2$, $X^2_2$: risultati al secondo lancio  

Definiamo la somma:

$$
S_i = X^1_i + X^2_i
$$

$S_i$ Ã¨ la somma dei due dadi nellâ€™esperimento $i$-esimo.  
Tutte queste sono variabili casuali, ciascuna con la propria aspettativa.

---

## ğŸ”¹ 2.1.4 â€“ LinearitÃ  dellâ€™aspettativa

Una delle proprietÃ  piÃ¹ eleganti e potenti:

$$
E[X + Y] = E[X] + E[Y]
$$

ed Ã¨ **sempre vera**, anche se $X$ e $Y$ **non sono indipendenti**.

---

### ğŸ’¡ Esempio 3 â€“ Due dadi

Lanci due dadi e definiamo:

$$
X_1 = \text{risultato del primo dado}, \quad X_2 = \text{risultato del secondo dado}
$$

Sia $X = X_1 + X_2$.  
Allora:

$$
E[X] = E[X_1 + X_2] = E[X_1] + E[X_2]
$$

PoichÃ© $E[X_1] = E[X_2] = 3.5$, otteniamo:

$$
E[X] = 3.5 + 3.5 = 7
$$

ğŸ‘‰ Il valore medio della somma dei due dadi Ã¨ **7**.

---

## ğŸ”¹ 2.1.5 â€“ Quando lâ€™aspettativa non esiste

Se i valori possibili di $X$ crescono troppo velocemente rispetto alle loro probabilitÃ ,  
la somma che definisce $E[X]$ **non converge**.

Esempio:

$$
X = 2^i \quad \text{con probabilitÃ } \quad \frac{1}{2^i}
$$

Allora:

$$
\sum_i 2^i \cdot \frac{1}{2^i} = \infty \quad \Rightarrow \quad E[X] = \infty
$$

Questo succede con **distribuzioni a coda pesante**, tipiche di fenomeni economici o di rete.

---

## ğŸ”¹ 2.1.6 â€“ Inizio: la disuguaglianza di Jensen

Spesso ci interessa non solo $E[X]$, ma anche $E[f(X)]$, cioÃ¨ la media di una funzione di $X$.  
Se $f$ Ã¨ **convessa**, allora vale la **disuguaglianza di Jensen**:

$$
E[f(X)] \ge f(E[X])
$$

---

### ğŸ’¡ Esempio 4 â€“ Lâ€™area di un quadrato

Sia $X$ la lunghezza del lato di un quadrato casuale e $f(X) = X^2$ la sua area.  
PoichÃ© $f$ Ã¨ convessa:

$$
E[X^2] > (E[X])^2
$$

ğŸ‘‰ La **media delle aree** Ã¨ piÃ¹ grande dellâ€™area calcolata sulla **media dei lati**.  
Questo spiega perchÃ© la varianza non Ã¨ mai nulla anche quando la media Ã¨ costante.

---

## ğŸ§© Sintesi finale

| **Concetto** | **Significato** | **Esempio / Formula** |
|:-------------|:----------------|:-----------------------|
| Variabile casuale | Funzione che assegna un numero a ogni esito possibile | $X : \Omega \to \mathbb{R}$ |
| ProbabilitÃ  di un valore | Quanto spesso $X$ assume un certo valore | $\Pr(X = x)$ |
| Aspettativa $E[X]$ | Media pesata dei valori di $X$ | $E[X] = \sum x \Pr(X = x)$ |
| LinearitÃ  | La media della somma Ã¨ la somma delle medie | $E[X + Y] = E[X] + E[Y]$ |
| Jensen | Per funzioni convesse: $E[f(X)] \ge f(E[X])$ | $E[X^2] > (E[X])^2$ |
| Indici $X_1, X_2$ | Sottoscritti = variabili diverse, soprascritti = esperimenti diversi | $S_i = X^1_i + X^2_i$ |
# ğŸ“˜ Capitolo 2 â€“ Variabili casuali discrete e aspettativa  
## ğŸ”¹ Pagine 27â€“32 â€“ Variabili Bernoulli, Binomiali e Aspettativa Condizionata

---

## ğŸ§© Introduzione

Abbiamo imparato che una **variabile casuale** (o *aleatoria*) Ã¨ una funzione che associa un numero a un evento casuale.  
Ora ci concentriamo su due tipi fondamentali di variabili discrete â€” **Bernoulli** e **Binomiale** â€” e su come calcolare **aspettative condizionate**, cioÃ¨ medie â€œsapendo che qualcosa Ã¨ successoâ€.

Queste idee sono la base della probabilitÃ  applicata, dagli algoritmi randomizzati alle simulazioni statistiche.

---

## ğŸ”¹ 2.2 â€“ Variabili casuali Bernoulli e binomiali

### ğŸ¯ Variabile di Bernoulli

La **variabile di Bernoulli** Ã¨ il modello piÃ¹ semplice: puÃ² valere solo 0 o 1.

$$
X =
\begin{cases}
1 & \text{con probabilitÃ  } p \\
0 & \text{con probabilitÃ  } 1 - p
\end{cases}
$$

ğŸ“˜ **Interpretazione pratica:**

- $1$ = successo (es. â€œesce testaâ€, â€œevento accadutoâ€)  
- $0$ = fallimento

---

### ğŸ’¡ Esempio intuitivo

Lancio una moneta con probabilitÃ  $p = 0.7$ di testa.  
Definisco $X = 1$ se esce testa, $X = 0$ se esce croce.  
â†’ $X$ Ã¨ una variabile di Bernoulli.

---

### ğŸ“Š Aspettativa e varianza

$$
E[X] = 1 \cdot p + 0 \cdot (1 - p) = p
$$

ğŸ‘‰ In media, il valore di $X$ coincide con la **probabilitÃ  di successo**.

La **varianza**, cioÃ¨ quanto $X$ varia rispetto alla sua media, Ã¨:

$$
\mathrm{Var}(X) = p(1 - p)
$$

ğŸ“ˆ Ãˆ massima quando $p = 0.5$, cioÃ¨ quando il risultato Ã¨ piÃ¹ incerto.

---

## ğŸ”¹ Variabile Binomiale

Ora immaginiamo di ripetere lâ€™esperimento **n volte**, in modo indipendente.  
Ogni prova ha probabilitÃ  $p$ di successo.  
Definiamo:

$$
X_i =
\begin{cases}
1 & \text{se la i-esima prova Ã¨ un successo} \\
0 & \text{altrimenti}
\end{cases}
$$

La **somma dei successi**:

$$
X = X_1 + X_2 + \dots + X_n
$$

Ã¨ una **variabile binomiale**.  
Essa conta **quanti successi** otteniamo in $n$ prove.

---

### ğŸ§® Distribuzione binomiale

$$
\Pr(X = k) = \binom{n}{k} p^k (1 - p)^{n - k}
$$

ğŸ“˜ Dove:
- $n$ = numero di prove  
- $k$ = numero di successi  
- $p$ = probabilitÃ  di successo per prova  

$$
\binom{n}{k} = \frac{n!}{k! \, (n - k)!}
$$

rappresenta il numero di modi per scegliere **quali** prove risultano vincenti.

---

### ğŸ” Come leggere la formula

- Il termine $p^k (1 - p)^{n - k}$ Ã¨ la probabilitÃ  di **una singola sequenza** con $k$ successi e $n - k$ fallimenti.  
- Il coefficiente $\binom{n}{k}$ conta **tutte le sequenze** possibili che producono $k$ successi.  
- Moltiplicando otteniamo la probabilitÃ  complessiva di ottenere **esattamente k successi**.

---

### ğŸ’¡ Esempio concreto

Lancio una moneta equa ($p = 0.5$) tre volte.  
Voglio la probabilitÃ  di ottenere 2 teste:

$$
\Pr(X = 2) = \binom{3}{2} (0.5)^2 (0.5)^1 = 3 \times 0.25 \times 0.5 = 0.375
$$

ğŸ‘‰ ProbabilitÃ  = **37,5%**

---

### ğŸ¯ Esempio generale

Immagina un test con 10 domande a scelta multipla,  
e ogni risposta ha probabilitÃ  $p = 0.25$ di essere giusta â€œa casoâ€.

La probabilitÃ  di azzeccarne esattamente 4 Ã¨:

$$
\Pr(X = 4) = \binom{10}{4} (0.25)^4 (0.75)^6 \approx 0.146
$$

ğŸ‘‰ Circa **14,6%**.

---

## âš™ï¸ Aspettativa e varianza della binomiale

Usiamo la **linearitÃ  dellâ€™aspettativa**:

$$
E[X] = E[X_1 + X_2 + \dots + X_n] = E[X_1] + \dots + E[X_n]
$$

PoichÃ© ogni $E[X_i] = p$, abbiamo:

$$
E[X] = n p
$$

ğŸ‘‰ In media, ci aspettiamo **$n p$ successi** su $n$ prove.

---

### Varianza

PoichÃ© le prove sono indipendenti:

$$
\mathrm{Var}(X) = \mathrm{Var}(X_1 + X_2 + \dots + X_n) = \mathrm{Var}(X_1) + \dots + \mathrm{Var}(X_n)
$$

e dato che $\mathrm{Var}(X_i) = p(1 - p)$:

$$
\mathrm{Var}(X) = n p (1 - p)
$$

La **deviazione standard** Ã¨:

$$
\sigma = \sqrt{n p (1 - p)}
$$

---

### ğŸ’¬ Interpretazione intuitiva

Se lanci una moneta 100 volte ($n = 100$, $p = 0.5$):

$$
E[X] = 100 \times 0.5 = 50
$$
$$
\sigma = \sqrt{100 \times 0.5 \times 0.5} = 5
$$

ğŸ‘‰ In media ottieni 50 teste, con oscillazioni tipiche di Â±5.  
Risultati tra 45 e 55 sono i piÃ¹ probabili; 20 o 80 sono estremamente rari.

---

### ğŸ§  Osservazione importante

Il valore atteso $E[X]$ **non indica la probabilitÃ ** che accada qualcosa,  
ma la **media numerica** dei valori che $X$ assume.

$$
\Pr(X = E[X]) \text{ puÃ² essere basso, ma } E[X] \text{ rappresenta il â€œcentroâ€ della distribuzione.}
$$

---

## ğŸ”¹ 2.3 â€“ Aspettativa condizionata (introduzione)

Spesso vogliamo capire lâ€™**aspettativa sapendo che Ã¨ accaduto un certo evento**.

La **media condizionata** di $X$ dato un evento $A$ si scrive:

$$
E[X \mid A] = \sum_x x \cdot \Pr(X = x \mid A)
$$

Essa rappresenta la **media dei valori di X considerando solo i casi in cui A Ã¨ vero.**

---

### ğŸ’¡ Esempio

Sia $X$ il numero di teste in due lanci di moneta.  
Abbiamo $E[X] = 1$.

Se sappiamo che Ã¨ uscita almeno una testa (evento $A$), i casi possibili sono:

$$
\{ TH, HT, HH \}
$$

Allora:

$$
E[X \mid A] = \frac{1 + 1 + 2}{3} = \frac{4}{3}
$$

ğŸ‘‰ Sapendo che Ã¨ uscita almeno una testa, ci aspettiamo **1,33 teste in media.**

---

## ğŸ”¹ Legge delle aspettative totali

Una proprietÃ  fondamentale:

$$
E[X] = E[E[X \mid A]]
$$

CioÃ¨:  
> la media complessiva Ã¨ la media delle **medie condizionate**,  
> pesate con le probabilitÃ  degli eventi corrispondenti.

---

### ğŸ’¡ Esempio pratico

Supponiamo che un algoritmo funzioni su due tipi di input:

| Tipo | ProbabilitÃ  | Tempo medio |
|:-----|:-------------|:-------------|
| Facile | 0.8 | 5s |
| Difficile | 0.2 | 20s |

Allora:

$$
E[\text{tempo}] = 0.8 \times 5 + 0.2 \times 20 = 8 \text{ secondi}
$$

ğŸ‘‰ Lâ€™aspettativa globale Ã¨ la **media ponderata** delle aspettative condizionate.
## ğŸ¯ Introduzione

Finora abbiamo visto **variabili casuali binomiali**, che contano **quanti successi** avvengono in un numero fisso di prove.  
Ora cambiamo prospettiva: vogliamo sapere **quante prove servono prima di ottenere il primo successo**.

ğŸ‘‰ Questo Ã¨ il punto di partenza per la **distribuzione geometrica**.

---

## ğŸ”¹ 2.4 â€“ La distribuzione geometrica

### ğŸ”¸ Definizione

La variabile geometrica $X$ rappresenta il **numero di prove necessarie fino al primo successo** in una sequenza di esperimenti indipendenti,  
ognuno con probabilitÃ  di successo $p$.

$$
\Pr(X = k) = (1 - p)^{k - 1} p, \quad k = 1, 2, 3, \dots
$$

ğŸ“˜ **Significato:**

- Le prime $(k - 1)$ prove **falliscono** (ognuna con probabilitÃ  $(1 - p)$)  
- La $k$-esima prova Ã¨ un **successo** (con probabilitÃ  $p$)

---

### ğŸ’¡ Esempio intuitivo

Lancio una moneta e voglio sapere **quanti lanci servono prima di ottenere testa**, con $p = 0.5$:

$$
\Pr(X = 1) = 0.5 \quad \text{â†’ testa al primo lancio}
$$

$$
\Pr(X = 2) = 0.5^2 = 0.25 \quad \text{â†’ croce, poi testa}
$$

$$
\Pr(X = 3) = 0.5^3 = 0.125 \quad \text{â†’ due croci, poi testa}
$$

...e cosÃ¬ via.

---

## âš™ï¸ Aspettativa della distribuzione geometrica

Il numero medio di prove necessarie per il primo successo Ã¨:

$$
E[X] = \frac{1}{p}
$$

ğŸ‘‰ Se la probabilitÃ  di successo Ã¨ bassa, servono **piÃ¹ prove in media**.

| $p$ | $E[X]$ | Significato |
|:---:|:-------:|:------------|
| 0.5 | 2 | in media, due lanci per una testa |
| 0.1 | 10 | in media, dieci tentativi per un successo |
| 0.01 | 100 | eventi molto rari â†’ attese lunghe |

---

## âš–ï¸ Varianza della geometrica

$$
\mathrm{Var}(X) = \frac{1 - p}{p^2}
$$

ğŸ‘‰ La variabilitÃ  cresce molto quando il successo Ã¨ raro ($p$ piccolo).

---

## ğŸ§­ Interpretazione intuitiva

La **distribuzione geometrica** modella il tempo di attesa fino al primo evento â€œpositivoâ€.  
Ãˆ il modello naturale per situazioni del tipo:

- primo successo in una sequenza di esperimenti,  
- primo pacchetto corretto in una rete rumorosa,  
- prima collisione evitata in un sistema casuale.

ğŸ“ˆ Ãˆ la base per descrivere **tempi di attesa** e **conteggi di tentativi** nei processi casuali.
