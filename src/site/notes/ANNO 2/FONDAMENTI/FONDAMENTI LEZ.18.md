---
{"dg-publish":true,"permalink":"/anno-2/fondamenti/fondamenti-lez-18/"}
---

#### Questa lezione riprende due teoremi principali e i conseguenti concetti
![Pasted image 20250415101811.png](/img/user/ANNO%202/FONDAMENTI/fotofond/Pasted%20image%2020250415101811.png)

## Ora procediamo a vedere due esempi di PDA per i due tipi di accettazione

#### ESEMPIO 1: PDA che accetta per pila vuota
Costruiamo un PDA $$„Äà \{a,b\}, \ \{Z_{0}, A, B\}, \ Z_{0} , \ \{q_{0} , q_{1} \} , \ \varnothing, \ q_{0} , \ Œ¥ „Äâ$$
>[!bug] non so perch√© ma la prof ha invertito l'insieme degli stati(quelli in pos 4) con $Z_0$, essi andrebbero scambiati per definizione vista in [[ANNO 2/FONDAMENTI/FONDAMENTI LEZ.17#PDA\|FONDAMENTI LEZ.17#PDA]]

Questa PDA riconosce per pila vuota perch√© come stato finale ha un insieme vuoto
- pu√≤ terminare solo con pila vuota
- riconosce le parole di $L_{PPAL}$ 
queste sono le varie transizioni della funzione:
![Pasted image 20250415103131.png](/img/user/ANNO%202/FONDAMENTI/fotofond/Pasted%20image%2020250415103131.png)

- riempie la pila finch√©:
	- non raggiungiamo met√† della parola da leggere
- In questa fase, per ogni simbolo letto dall'input, controlla se **corrisponde al simbolo in cima alla pila**:
    - Se corrisponde, lo **rimuove dalla pila**
    - Altrimenti, la computazione **fallisce**
- Se al termine dell‚Äôinput la **pila risulta completamente vuota**, allora la parola √® **palindroma e di lunghezza pari**, e quindi **accettata**.
>[!question] come faccio a dirgli di comportarsi diversamente dopo la met√†?
>Il cambio di comportamento (da ‚Äúaccumulo‚Äù a ‚Äúcontrollo‚Äù) **non √® scritto 
>esplicitamente nel testo o nella struttura del PDA**, ma **√® gestito dal non 
>determinismo** grazie alle transizioni:
>![Pasted image 20250415103800.png](/img/user/ANNO%202/FONDAMENTI/fotofond/Pasted%20image%2020250415103800.png)
> √à il PDA che decide ‚Äúquando basta‚Äù e passa a controllare.  
> Non c‚Äô√® un contatore della lunghezza, **non ne ha bisogno**.

- praticamente una volta raggiunta la met√† inizia a svuotare la pila ma continua a leggere a destra ci√≤ che avviene nella stringa di input
	- se i caratteri corrispondono allora significa che si pu√≤ eliminare il tutto

![Pasted image 20250415104003.png](/img/user/ANNO%202/FONDAMENTI/fotofond/Pasted%20image%2020250415104003.png)
>[!attention] quindi una PDA pu√≤ essere non deterministico
>- quando non sa che fare crea due rami della stessa istanza per fare due scelte diverse

#### ESEMPIO 2: PDA che accetta per stato finale
Ora, costruiamo un PDA $$„Äà \{a,b\}, \ \{Z_{0}, A, B\}, \ Z_{0} , \ \{q_{0} , q_{1}, q_{2} \} , \ \{q_{2}\}, \ q_{0} , \ Œ¥ „Äâ$$che riconosce **PER STATO FINALE** ($q_{2}$) il linguaggio $L_{PPAL}$ delle parole palindrome pari sull'alfabeto $\{a,b\}$ 
queste sono le varie transizioni della funzione:
![Pasted image 20250415104720.png](/img/user/ANNO%202/FONDAMENTI/fotofond/Pasted%20image%2020250415104720.png)
Quindi
- finch√© si trova PRIMA della met√† aggiunge parole alla pila (NON CANCELLANDO $Z_{0}$)
- quando arriva alla met√†, se pu√≤, cancella
- se cancella tutto e arriva a leggere, di nuovo, $Z_{0}$, entra in $q_{2}$ **e accetta**
anche qui si applica il non determinismo perch√© "a una certa" deve cambiare modo di fare
![Pasted image 20250415104836.png](/img/user/ANNO%202/FONDAMENTI/fotofond/Pasted%20image%2020250415104836.png)
## Vogliamo simulare un PDA con una Macchina di Turing
Visto che si assomigliano, hanno nastri ecc...
si possono fare simulazioni di questo genere
√® a titolo di esempio quindi penso sia un po' inutile
![Pasted image 20250415105239.png](/img/user/ANNO%202/FONDAMENTI/fotofond/Pasted%20image%2020250415105239.png)
>[!tip]- spiegazione chiara di tutto ci√≤ che sta sopra:
> üéØ Obiettivo
> Dimostrare che una Macchina di Turing (TM) pu√≤ simulare un PDA, cio√® che ogni linguaggio accettato da un PDA per pila vuota pu√≤ essere accettato da una TM deterministica.
> 
> Questo dimostra che PDA ‚äÜ TM, ovvero che i linguaggi context-free sono riconoscibili anche da una macchina di Turing.
>---
> 
> üß© Componenti in gioco
> 
> Il PDA √® definito come:
> 
> ```
> A = ‚ü® Œ£, Œì, Q, Z‚ÇÄ, Q‚Çê, ‚àÖ, Œ¥ ‚ü©
> ```
> 
> - Œ£: alfabeto di input
> - Œì: alfabeto della pila
> - Q: stati del PDA
> - Z‚ÇÄ: simbolo iniziale della pila
> - Q‚Çê: stati accettanti della TM (non del PDA)
> - Œ¥: funzione di transizione del PDA
> 
> ‚ö†Ô∏è Il PDA accetta per **pila vuota**, quindi non ha stati finali propri (`‚àÖ` in sesta posizione).
> 
> ---
> üî® Costruzione della TM che simula il PDA
> 
> Costruiamo una TM `T` come:
> 
> ```
> T = ‚ü® Œ£ ‚à™ Œì, Q_T, q‚ÇÄ, {q‚Çê}, P ‚ü©
> ```
> 
> - Œ£ ‚à™ Œì: l‚Äôalfabeto comprende sia input che pila (la TM li tratta come simboli sul nastro)
> - Q_T = Q ‚à™ {q‚Çê}: stati del PDA pi√π un nuovo stato finale q‚Çê
> - q‚ÇÄ: stato iniziale della TM
> - q‚Çê: stato accettante della TM
> - P: insieme delle transizioni (quintupla) della TM
> 
> ---
> 
> üîÅ Simulazione delle transizioni del PDA nella TM
> 
> ‚úÖ Caso 1: Transizione semplice con Œµ
> 
> Se:
> ```
> (q‚ÇÇ, Œ≥) ‚àà Œ¥(q‚ÇÅ, a, Z)
> ```
> 
> Allora in P si inserisce:
> ```
> ‚ü®q‚ÇÅ, (a, Z), (a, 1), q‚ÇÇ, D‚ü©
> ```
> 
> - Leggi `a` e `Z`
> - Scrivi `a` (o lo lasci uguale), scrivi `1` al posto di `Z`
> - Vai a `q‚ÇÇ`, muovi a destra
> 
> ---
> ‚úÖ Caso 2: Transizione che spinge pi√π simboli
> 
> Se:
> ```
> (q‚ÇÇ, Z‚ÇÅZ‚ÇÇ...Z‚Çñ) ‚àà Œ¥(q‚ÇÅ, a, Z)
> ```
> 
> - Si creano stati temporanei in Q_T per gestire ciascun push
> - Si scrivono i simboli sulla ‚Äúpila‚Äù della TM da destra a sinistra:
>   ```
>   Z‚Çñ, Z‚Çñ‚Çã‚ÇÅ, ..., Z‚ÇÅ
>   ```
> 
> ---
> ‚úÖ Caso 3: Transizione con Œµ sull'input
> 
> Se:
> ```
> (q‚ÇÇ, Œ≥) ‚àà Œ¥(q‚ÇÅ, Œµ, Z)
> ```
> 
> Per ogni `a ‚àà Œ£`, si inserisce:
> ```
> ‚ü®q‚ÇÅ, (a, Z), (a, 1), q‚ÇÇ, D‚ü©
> ```
> 
> Serve per simulare le transizioni del PDA che agiscono **solo sulla pila**.
> 
> ---
> ‚úÖ Caso finale: accettazione per pila vuota
> 
> Alla fine, per ogni `q ‚àà Q`, se la pila √® vuota, si inserisce:
> ```
> ‚ü®q, (‚ä•, ‚ä•), (‚ä•, ‚ä•), q‚Çê, (F, F)‚ü©
> ```
> 
> (‚ä• = simbolo di margine o vuoto)
> 
> ---
> ‚úÖ Conclusione
> 
> La TM costruita simula fedelmente le transizioni del PDA, accettando **se e solo se** il PDA avrebbe svuotato la pila.
> 
> Quindi:
> ```
> L(N(M)) ‚äÜ L(TM)
> ```
> 

>[!question] ESERCIZIO da fare: dimostrare l'equivalenza di A e T

### Fino ad ora
fino ad ora abbiamo creato delle funzioni che si limitano a 
- consumare un elemento a
- non consumare un elemento a
quindi sostanzialmente abbiamo l'unione di queste due funzioni 
$$ ùúπ(q_{1} , a, Z) ‚à™ ùúπ(q_{1}, ùú∫, Z)$$
con un PDA non deterministico e che in questo caso si riferisce solo a q1


### Invece un PDA deterministico?
semplicemente per renderlo deterministico per: 
- ogni stato interno $ùúπ$ 
- ogni simbolo sul nastro 
- ogni azione da scegliere
sia solo e soltanto una

>[!lemma] DEFINIZIONE
>Un PDA $$‚Ñ≥=„Äà Œ£, \ Œì , \ Z_{0} , \ Q , \ Q_{F} , \ q_{0} , \ Œ¥ „Äâ$$ √® deterministico se ogni $q ‚àà Q$, per ogni $a ‚àà Œ£$, e per ogni $Z ‚àà Œì$ accade che $$|\delta(q_{1}, a, Z)| \ + \ |\delta(q_{1}, \varepsilon, Z)| \ = \ 1 $$

in poche parole la somma delle azioni per un dato simbolo e stato interno deve essere 1, quindi una delle due $\nexists$
###### Una piccola differenza
Sappiamo che dal punto di vista della calcolabilit√†, una Macchina di Turing NON DETERMINISTICA √® equivalente a una Macchina di Turing DETERMINISTICA
	ossia, tutto ci√≤ che possiamo fare con la NON DETERMINISTICA lo possiamo possiamo fare anche con la DETERMINISTICA

>[!question] Vale lo stesso per i PDA?
>No, perch√© esistono dei **linguaggi context-free che non sono accettati da automi a pila non deterministici**

da qui viene un teorema:

>[!lemma] TEOREMA G.12
> L‚Äôinsieme dei linguaggi accettati da automi a pila deterministici √® un sottoinsieme proprio ($\subset$) dei linguaggi context-free
> 
> In altri termini, *gli automi a pila deterministici sono ‚Äò‚Äôstrettamente meno potenti‚Äô‚Äô di quelli non deterministici*.


##### Conclusione Macchina di Turing VS PDA
>[!question] üîç La domanda che la prof si pone √®:
> *Se possiamo trasformare (lez. iniziali) un PDA non deterministico (NPDA) in una macchina di Turing non deterministica (NTM), e poi una NTM in una deterministica (DTM)‚Ä¶*  
> *allora perch√© non possiamo "rientrare" e costruire un **DPDA** equivalente?*

>[!todo] üö® Risposta:
> **Perch√© non sappiamo trasformare una DTM in un PDA deterministico!**

Cio√®:
- Possiamo partire da NPDA ‚Üí NTM ‚Üí DTM, e accettare i linguaggi.
- Ma **non possiamo tornare indietro da DTM ‚Üí DPDA**, perch√©:
    - I PDA hanno **meno memoria** (solo una pila).
    - E **non possono simulare ogni DTM**.

>[!tip] ‚úÖ Quindi:
> - Ogni linguaggio context-free √® **accettato da una macchina di Turing** (deterministica).
> - Ma non tutti i linguaggi context-free sono accettabili da un **DPDA**.
> 

## Alberi sintattici üå≥
√à un classico albero informatico con
- nodi 
- rami
- foglie
che rappresenta il processo di derivazione di una parola secondo le regole della grammatica viste nelle lezioni scorse
### Come √® strutturato per essere applicato alle grammatiche
#### üîç Struttura dell‚Äôalbero sintattico:
- **Radice = S**  
    Parte sempre dal simbolo iniziale della grammatica (cio√® il punto di partenza della derivazione).

- **Nodi interni = simboli non terminali** (cio√® ‚àà V<sub>N</sub>)  
    Questi sono i simboli che vengono _espansi_ secondo le regole di produzione.
    
- **Foglie = simboli terminali** (cio√® ‚àà V<sub>T</sub>)  
    Sono i caratteri finali della parola generata (quelli che _vedi nell'output_).
    
- **Espansione dei nodi** Rami:  
    Se in una regola hai per esempio `A ‚Üí x‚ÇÅ x‚ÇÇ ... x‚Çô`,  
    allora nel tuo albero:
    - `A` sar√† un **nodo interno**
    - `x‚ÇÅ, x‚ÇÇ, ..., x‚Çô` saranno i suoi **figli**, nell‚Äôordine indicato dalla produzione.

>[!success] gli alberi sintattici servono per fornire una desrizione sintetica di come √® strutturata sintatticamente una parola
>- ti mostra quali produzioni l'hanno generata

## ESEMPIO PRATICO
![Pasted image 20250415112143.png](/img/user/ANNO%202/FONDAMENTI/fotofond/Pasted%20image%2020250415112143.png)
>[!tip] L'osservazione √® molto importante perch√© dice uno stesso albero sintattico corrisponde a pi√π di una derivazione.

Significa che una stessa parola pu√≤ essere generata in modi diversi, cio√® seguendo derivazioni diverse, ma che alla fine portano allo stesso albero sintattico.

Quindi da un albero sintattico possono corrispondere pi√π derivazioni

>[!bug] per√≤ c'√® un problema ovvero che una singola parola pu√≤ corrispondere pi√π di un albero sintattico
>- ecco un esempio
>- questo pu√≤ causare ambiguit√† di lettura della parola
>![Pasted image 20250415112448.png](/img/user/ANNO%202/FONDAMENTI/fotofond/Pasted%20image%2020250415112448.png)


√® un problema perch√© gli alberi sintattici sono usati anche per capire il significato delle parole al livello anche semantico, questi due alberi danno un significato differente
Prendiamo l'esempio nella foto, e ipotizziamo che l'albero sia impostato per interpretare la parola generata **PARTENDO DAL BASSO**
1. <font color="#d83931">ALBERO IN ROSSO</font>: `3 + (3 * 3) = 12`
2. <font color="#245bdb">ALBERO IN BLU</font>: `(3 + 3) * 3 = 18`

Sarebbe veramente bello poter capire in anticipo se una grammatica sia ambigua o no MA OVVIAMENTE NON SI PU√í FARE.

Da qui viene fuori il teorema che d√† dei dettagli sulle ambiguit√†

>[!lemma] Teorema G.13
>sia $L_{A}$ l‚Äôinsieme delle grammatiche di tipo 2 ambigue -> **il linguaggio** $L_{A}$ **√® non decidibile**.
>
>Ci√≤ significa che non esiste un algoritmo che, data una grammatica G di tipo 2 decide se G √® ambigua


>[!tip]- Chiacchiere finali della prof 
>1. üìå **I linguaggi di programmazione ‚Äúgrosso modo‚Äù sono di tipo 2 (context-free)**:
>    - Ovvero: la **struttura sintattica di base** di un linguaggio di programmazione pu√≤ essere espressa con una grammatica context-free.
>        
>    - Tuttavia, **alcune regole**, come per esempio **l‚Äôunicit√† della dichiarazione di una variabile**, richiedono controlli pi√π potenti ‚Üí cio√® **di tipo 1** (context-sensitive).
>    
>1. üí° **Si possono separare** gli aspetti:
>    - Di tipo 2: la struttura del programma.
>    - Di tipo 1: le regole contestuali, come i nomi unici, i tipi delle variabili ecc.
>    
>1. üîç L‚Äôanalisi sintattica (`parsing`):
>    - Viene **divisa in due fasi**: una per controllare la struttura generale (tipo 2), l‚Äôaltra per gli aspetti contestuali (tipo 1).
>    
>1. ‚öôÔ∏è Il `parsing` √® **la fase di verifica della correttezza** del programma:
>    - Serve **prima** della traduzione in codice eseguibile.
>    - In questa fase si costruisce **l‚Äôalbero sintattico** della frase/programmazione.
>    - Da questo albero poi **si genera il codice oggetto** (eseguibile).
>	
>1. üìö Le grammatiche formali sono nate per **descrivere le frasi nei linguaggi naturali**, ma...
>    - ...sono risultate **inadatte** a quello scopo.    
>    - Tuttavia, si sono rivelate perfette per **analizzare i linguaggi di programmazione**.
>    
>1. üí° **A cosa servono** nei linguaggi di programmazione?
>    - Per **studiare la sintassi**.
>    - Per **descrivere formalmente** se un programma √® corretto dal punto di vista sintattico.
>    
>1. üß† Ogni linguaggio di programmazione pu√≤ essere associato a una grammatica $G_{P}$‚Äã:
>    - Un **programma √® sintatticamente corretto** se √® una parola del linguaggio generato da $G_{P}$‚Äã.