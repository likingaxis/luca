---
{"dg-publish":true,"permalink":"/anno-3/intelligenza-artificiale/ia-argomenti-esonero-1/"}
---

### ğŸ›ï¸Â **Parte 1: Fondamenti dell'Intelligenza Artificiale**

Questa sezione introduce i concetti base, le definizioni e i diversi approcci filosofici all'IA.

- **ğŸ§  Introduzione e Cos'Ã¨ l'IA (Pag. 1)**
    
    - **Agire Umanamente: L'Approccio del Test di Turing**
        
        - **Test di Turing:**Â Scopo (una macchina Ã¨ in grado di pensare?), funzionamento (esaminatore umano che interroga via testo) e criterio di superamento.
            
        - **CapacitÃ  richieste:**Â Interpretazione del linguaggio naturale, rappresentazione della conoscenza, ragionamento automatico, apprendimento automatico (Machine Learning).
            
        - **Test di Turing Totale:**Â Aggiunge l'interazione con il mondo fisico, richiedendo visione artificiale e robotica.
            
    - **Pensare Umanamente: L'Approccio della Modellazione Cognitiva**
        
        - **Metodi di analisi:**Â Introspezione, sperimentazione psicologica, imaging cerebrale.
            
        - **Scienze Cognitive:**Â Campo interdisciplinare che unisce modelli computazionali dell'IA e tecniche psicologiche.
            
    - **Agire Razionalmente: L'Approccio degli Agenti Razionali**
        
        - **Agente:**Â Qualsiasi cosa che agisce.
            
        - **Agente Razionale:**Â Agisce per ottenere il miglior risultato possibile, anche in condizioni di incertezza.
            

---

### ğŸ¤–Â **Parte 2: Agenti Intelligenti**

Qui si definisce il paradigma centrale del corso: l'agente. Si analizza come interagisce con l'ambiente e come si misura la sua efficacia.

- **ğŸŒ Agenti e Ambienti (Pag. 2-6)**
    
    - **Definizione di Agente:**Â Un sistema che percepisce l'ambiente tramiteÂ **sensori**Â e agisce su di esso tramiteÂ **attuatori**.
        
    - **Percezione (Percept) e Sequenza Percettiva:**Â I dati raccolti dai sensori e la storia completa di tutte le percezioni.
        
    - **Funzione Agente:**Â La mappatura astratta tra sequenze percettive e azioni.
        
    - **Programma Agente:**Â L'implementazione concreta della funzione agente.
    - **Il Ciclo dell'Agente (4 fasi):**Â La scomposizione del ciclo inÂ percepire -> decidere -> agire -> aggiornareÂ Ã¨ una formalizzazione molto utile.
        
- **ğŸ‘ Comportarsi Correttamente: Il Concetto di RazionalitÃ  (Pag. 3-4)**
    
    - **Misure di Prestazione:**Â Criterio oggettivo per valutare il successo del comportamento di un agente.
        
    - **Definizione di RazionalitÃ :**Â Dipende da 4 fattori: misura di prestazione, conoscenza pregressa, azioni possibili, sequenza percettiva corrente.
        
    - **Definizione di Agente Razionale:**Â Per ogni sequenza di percezioni, sceglie l'azione che massimizza il valore atteso della misura di prestazione.
        
    - **Onniscienza vs RazionalitÃ :**Â Un agente onnisciente conosce l'esito reale delle azioni, un agente razionale massimizza l'esitoÂ atteso.
        
    - **Information Gathering (Raccolta di Informazioni) e Autonomia:**Â La capacitÃ  di apprendere dalle proprie percezioni per diventare indipendente dalla conoscenza iniziale del progettista.
        
- **ğŸ” La Natura degli Ambienti (Pag. 4-6)**
    
    - **Ambiente Operativo (Task Environment):**Â La descrizione di un problema attraverso il modelloÂ **PEAS**:
        
        - **P**erformance (Prestazione)
            
        - **E**nvironment (Ambiente)
            
        - **A**ctuators (Attuatori)
            
        - **S**ensors (Sensori)
            
        - Esempio: Guidatore di taxi automatizzato.
            
    - **ProprietÃ  degli Ambienti Operativi:**
        
        - **Osservabile (Completamente/Parzialmente):**Â L'agente ha accesso allo stato completo dell'ambiente?
            
        - **Agenti (Singolo/Multiagente):**Â Ci sono altri agenti nell'ambiente?
            
        - **Deterministico/Stocastico:**Â L'esito di un'azione Ã¨ certo o probabilistico?
            
        - **Episodico/Sequenziale:**Â La decisione corrente dipende dalle decisioni passate?
            
        - **Statico/Dinamico:**Â L'ambiente cambia mentre l'agente decide? (Semidinamico se cambia solo la misura di prestazione).
            
        - **Discreto/Continuo:**Â Lo stato, il tempo e le azioni sono finiti o infiniti?
            
        - **Noto/Ignoto:**Â Le "leggi fisiche" dell'ambiente sono conosciute dall'agente?
            

---

### âš™ï¸Â **Parte 3: La Struttura degli Agenti**

Questa sezione descrive le "ricette" per costruire programmi agente, dai piÃ¹ semplici ai piÃ¹ complessi.

- **ğŸ—ï¸ Architettura e Programmi Agente (Pag. 8)**
    
    - **Equazione fondamentale:**Â agente = architettura + programma.
        
    - **Sfida dell'IA:**Â Creare comportamento razionale con codice compatto, evitando tabelle esplicite (impossibili da gestire per la loro dimensione).
        
- **Tipi di Programmi Agente (Pag. 9-14)**
    
    - **1. Agenti Reattivi Semplici:**
        
        - **Funzionamento:**Â Basati su regoleÂ condizione-azioneÂ (if-then).
            
        - **Limiti:**Â Ignorano la storia percettiva, funzionano solo in ambienti completamente osservabili, possono entrare in cicli infiniti.
            
    - **2. Agenti Reattivi Basati su Modello:**
        
        - **Funzionamento:**Â Mantengono unoÂ **stato interno**Â per tener traccia del mondo non osservabile.
            
        - **Componenti chiave:**Â **Modello di transizione**Â (come evolve il mondo) eÂ **modello sensoriale**Â (come le percezioni si legano allo stato).
            
    - **3. Agenti Basati su Obiettivi:**
        
        - **Funzionamento:**Â Oltre allo stato, hanno informazioni sugliÂ **obiettivi**Â (goal), ovvero situazioni desiderabili.
            
        - **CapacitÃ :**Â Prendono decisioni considerando il futuro (**ricerca e pianificazione**). Sono piÃ¹ flessibili degli agenti reattivi.
            
    - **4. Agenti Basati sull'UtilitÃ :**
        
        - **Funzionamento:**Â Usano unaÂ **funzione di utilitÃ **Â che mappa uno stato in un numero reale (grado di "contentezza").
            
        - **Vantaggi:**Â Gestiscono obiettivi contrastanti e incertezza, scegliendo l'azione che massimizza l'**utilitÃ  attesa**.
            
- **ğŸ“ Agenti Capaci di Apprendere (Pag. 13-14)**
    
    - **Vantaggio:**Â Possono operare in ambienti sconosciuti e migliorare nel tempo.
        
    - **Componenti Astratti:**
        
        - **Elemento di Apprendimento (Learning Element):**Â Responsabile dei miglioramenti.
            
        - **Elemento Esecutivo (Performance Element):**Â Sceglie le azioni (Ã¨ l'agente visto finora).
            
        - **Elemento Critico (Critic):**Â Fornisce feedback su come sta andando l'agente.
            
        - **Generatore di Problemi (Problem Generator):**Â Suggerisce azioni esplorative per acquisire nuove esperienze.
            
    - **Rappresentazioni dello Stato del Mondo:**
        
        - **Atomica:**Â Lo stato Ã¨ un blocco unico, senza struttura interna.
            
        - **Fattorizzata:**Â Lo stato Ã¨ un insieme di variabili/attributi.
            
        - **Strutturata:**Â Lo stato descrive oggetti e le loro relazioni.
            

---

### ğŸ—ºï¸Â **Parte 4: Risolvere i Problemi con la Ricerca**

Questa Ã¨ una delle sezioni piÃ¹ corpose. Descrive come un agente puÃ² trovare una sequenza di azioni per raggiungere un obiettivo quando la soluzione non Ã¨ ovvia.

- **ğŸ¯ Formulazione dei Problemi di Ricerca (Pag. 15-18)**
    
    - **Agente Risolutore di Problemi:**Â Trova sequenze di azioni per raggiungere uno stato obiettivo.
        
    - **Processo di Risoluzione:**
        
        1. **Formulazione dell'obiettivo.**
            
        2. **Formulazione del problema**Â (stati, azioni, ecc.).
            
        3. **Ricerca**Â di una soluzione (sequenza di azioni).
            
        4. **Esecuzione**Â della soluzione.
            
    - **Definizione Formale di un Problema:**
        
        - **Spazio degli stati.**
            
        - **Stato iniziale.**
            
        - **Azioni(s):**Â Azioni possibili in uno statoÂ s.
            
        - **Modello di transizione (Risultato(s, a)):**Â Lo stato risultante.
            
        - **Test di obiettivo.**
            
        - **Funzione di costo dell'azione.**
            
    - **Astrazione:**Â Il processo di rimuovere dettagli per creare un modello gestibile.
        
	- **Esempi di problemi:**Â Aspirapolvere, ricerca di itinerari, commesso viaggiatore (TSP), configurazione VLSI.
        
- **ğŸŒ² Algoritmi di Ricerca: Concetti Base (Pag. 18-20)**
    
    - **Albero di Ricerca:**Â Struttura dati creata dall'algoritmo per esplorare i cammini.
        
    - **Nodo:**Â Struttura dati che contiene:Â Stato,Â Padre,Â Azione,Â Costo-Cammino.
        
    - **Frontiera (o Coda):**Â Insieme dei nodi generati ma non ancora espansi.
        
    - **Criteri di Valutazione degli Algoritmi:**
        
        - **Completezza:**Â Trova sempre una soluzione se esiste?
            
        - **OttimalitÃ :**Â Trova la soluzione a costo minimo?
            
        - **ComplessitÃ  Temporale:**Â Quanto tempo ci mette?
            
        - **ComplessitÃ  Spaziale:**Â Quanta memoria usa?
            
- **ğŸ§­ Strategie di Ricerca Non Informata (Cieca) (Pag. 21-24)**
    
    - **Ricerca in Ampiezza (BFS):**
        
        - Espande il nodo piÃ¹ superficiale.
            
        - Completa e ottimale (se i costi sono uniformi).
            
        - ComplessitÃ  esponenzialeÂ O(b^d).
            
    - **Ricerca a Costo Uniforme (Dijkstra):**
        
        - Espande il nodo con il costo di camminoÂ g(n)Â piÃ¹ basso.
            
        - Completa e ottimale.
            
    - **Ricerca in ProfonditÃ  (DFS):**
        
        - Espande il nodo piÃ¹ profondo.
            
        - Non completa e non ottimale.
            
        - Bassa complessitÃ  spazialeÂ O(bm).
            
    - **Ricerca a ProfonditÃ  Limitata:**Â DFS con un limite di profonditÃ .
        
    - **Ricerca ad Approfondimento Iterativo:**Â Esegue DFS con limiti di profonditÃ  crescenti. Unisce i vantaggi di BFS e DFS.
    
	- **Direzione della Ricerca (Avanti vs. Indietro):**
        
    - **Ricerca Bidirezionale:**Â Cerca simultaneamente in avanti dallo stato iniziale e all'indietro dall'obiettivo.
        
- **ğŸ’¡ Strategie di Ricerca Informata (Euristica) (Pag. 25-34)**
    
    - **Funzione Euristica h(n):**Â Stima del costo dal nodoÂ nÂ all'obiettivo.
        
    - **Ricerca Best-First Greedy ("Golosa"):**
        
        - Espande il nodo cheÂ sembraÂ piÃ¹ vicino all'obiettivo,Â f(n) = h(n).
            
        - Non completa e non ottimale.
            
    - **Ricerca A*:**
        
        - **Formula chiave:**Â f(n) = g(n) + h(n).
            
        - g(n)Â = costo dal nodo iniziale aÂ n.
            
        - h(n)Â = costo stimato daÂ nÂ all'obiettivo.
            
        - Combina i vantaggi della ricerca a costo uniforme e della greedy.
            
    - **ProprietÃ  delle Euristiche:**
        
        - **AmmissibilitÃ :**Â Un'euristica Ã¨ ammissibile se non sovrastima mai il costo reale (h(n) <= h*(n)).Â **A* con euristica ammissibile Ã¨ ottimale.**
            
        - **Consistenza (MonotonicitÃ ):**Â ProprietÃ  piÃ¹ forte, implica l'ammissibilitÃ .
            
    - **Ricerca con Memoria Limitata:**
        
        - **IDA* (A* ad Approfondimento Iterativo):**Â UsaÂ f(n)Â come limite.
            
        - **RBFS (Ricerca Best-First Ricorsiva):**Â Simula A* in spazio lineare.
            
        - **SMA* (Simplified Memory-Bounded A*):**Â Dimentica i nodi peggiori quando la memoria Ã¨ piena.
            
    - **Generazione di Euristiche:**
        
        - **Problemi Rilassati:**Â Rimuovere vincoli dal problema originale.
            
        - **Database di Pattern:**Â Memorizzare i costi esatti per sottoproblemi.
            

---

### â›°ï¸Â **Parte 5: Altre Tipologie di Ricerca**

Questa parte esplora approcci di ricerca alternativi, adatti a problemi diversi da quelli classici "trova il cammino".

- **ğŸ” Ricerca Locale e Problemi di Ottimizzazione (Pag. 35-39)**
    
    - **Idea:**Â Non si tiene traccia del cammino, si lavora su uno stato corrente e si cerca di migliorarlo.
        
    - **Panorama dello Spazio degli Stati:**Â Metafora della superficie con picchi e valli.
        
    - **Hill Climbing ("Scalata della Collina"):**
        
        - Si muove sempre verso lo stato vicino migliore.
            
        - **Problemi:**Â Massimi locali, plateau (pianori), creste (ridges).
            
        - **Varianti:**Â Stocastico, con prima scelta, con riavvio casuale.
            
    - **Simulated Annealing:**
        
        - Permette mosse "peggiori" con una probabilitÃ  che diminuisce nel tempo (controllata da una "temperatura").
            
        - Aiuta a sfuggire ai massimi locali.
            
    - **Ricerca Local Beam:**Â MantieneÂ kÂ stati invece di uno solo e li espande in parallelo.
        
- **ğŸ² Ricerca in Ambienti Non Deterministici e Parzialmente Osservabili (Pag. 39-45)**
    
    - **Ricerca con Azioni Non Deterministiche:**
        
        - **Alberi di Ricerca AND-OR:**Â I nodiÂ ORÂ rappresentano le scelte dell'agente, i nodiÂ ANDÂ i possibili esiti dell'ambiente.
            
        - UnaÂ **soluzione**Â Ã¨ un piano condizionale (o strategia).
            
    - **Ricerca con Osservazioni Parziali:**
        
        - **Stato-Credenza (Belief State):**Â L'insieme di tutti gli stati fisici in cui l'agente potrebbe trovarsi.
            
        - La ricerca avviene nello spazio degli stati-credenza.
            
- **ğŸƒ Agenti per Ricerca Online (Pag. 45-47)**
    
    - **Caratteristica:**Â L'agente alterna computazione e azione in un ambiente sconosciuto.
        
    - **Ricerca Locale Online:**
        
        - **Hill Climbing Online:**Â Soffre dei massimi locali.
            
        - **LRTA* (Learning Real-Time A*):**Â Apprende e aggiorna i valori dell'euristica mentre esplora.
            

---

### ğŸ“šÂ **Parte 6: Agenti Logici**

L'ultima sezione introduce un modo completamente diverso di costruire agenti, basato sulla rappresentazione esplicita della conoscenza e sul ragionamento logico.

- **ğŸ§  Agenti Basati sulla Conoscenza (Pag. 47-48)**
    
    - **Base di Conoscenza (KB - Knowledge Base):**Â Un insieme di formule che rappresentano asserzioni sul mondo.
        
    - **Operazioni Fondamentali:**
        
        - **Tell:**Â Aggiungere una nuova formula alla KB.
            
        - **Ask:**Â Interrogare la KB.
            
    - **Inferenza:**Â Il processo di derivare nuove formule da quelle esistenti.
        
    - **Approccio Dichiarativo vs Procedurale.**
        
- **ğŸ“– Logica Proposizionale (Pag. 49-52)**
    
    - **Sintassi:**
        
        - **Simboli proposizionali**Â (P,Â Q, ...).
            
        - **Connettivi logici**Â (Â¬, âˆ§, âˆ¨, â‡’, â‡”).
            
    - **Semantica:**
        
        - **Modello:**Â Assegnazione di valori di veritÃ  (vero/falso) a ogni simbolo.
            
        - **Tavole di VeritÃ :**Â Definiscono il significato dei connettivi.
            
    - **Concetti per la Dimostrazione di Teoremi:**
        
        - **Equivalenza Logica:**Â Due formule sono vere nello stesso insieme di modelli.
            
        - **ValiditÃ  (Tautologia):**Â Una formula Ã¨ vera in tutti i modelli.
            
        - **SoddisfacibilitÃ :**Â Una formula Ã¨ vera in almeno un modello.
            
    - **Inferenza e Dimostrazioni:**
        
        - **Regole di Inferenza:**Â Meccanismi per derivare nuove formule (es.Â **Modus Ponens**).
            
        - **Dimostrazione per Risoluzione:**
            
            - **Forma Normale Congiuntiva (CNF):**Â Tutte le formule sono scritte come congiunzioni di clausole (disgiunzioni di letterali).
                
            - L'algoritmo di risoluzione Ã¨ completo per la logica proposizionale.
